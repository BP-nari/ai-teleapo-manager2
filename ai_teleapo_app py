import streamlit as st
import pandas as pd
import re
from datetime import datetime, timedelta
import hashlib
import json
import os
from pathlib import Path
import time
from io import BytesIO
import pickle

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIãƒ†ãƒ¬ã‚¢ãƒç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ã‚»ãƒ¼ãƒ«ã‚¹",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ç™½èƒŒæ™¯ã§è¦‹ã‚„ã™ã„é’ãƒ™ãƒ¼ã‚¹ã®ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* å…¨ä½“ã®èƒŒæ™¯ã‚’ç™½ã« */
    .stApp {
        background-color: #ffffff;
        color: #333333;
    }
    
    /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ */
    .main .block-container {
        background-color: #ffffff;
        padding: 2rem;
        max-width: 1200px;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ */
    .css-1d391kg {
        background-color: #f8fafc;
        border-right: 1px solid #e2e8f0;
    }
    
    /* ãƒ˜ãƒƒãƒ€ãƒ¼ */
    .main-header {
        font-size: 2.5rem;
        color: #1e40af;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 700;
        padding: 1rem 0;
        border-bottom: 3px solid #3b82f6;
    }
    
    /* ã‚¸ãƒ§ãƒ–ã‚«ãƒ¼ãƒ‰ - æ¸…æ½”æ„Ÿã®ã‚ã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ */
    .job-card {
        background: #ffffff;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        border: 2px solid #e2e8f0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        transition: all 0.3s ease;
    }
    
    .job-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(59, 130, 246, 0.15);
        border-color: #3b82f6;
    }
    
    .job-card-header {
        font-size: 1.3rem;
        font-weight: bold;
        color: #1e40af;
        margin-bottom: 1rem;
        border-bottom: 2px solid #3b82f6;
        padding-bottom: 0.5rem;
        display: flex;
        align-items: center;
        justify-content: space-between;
    }
    
    .job-info-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
        gap: 1rem;
        margin-top: 1rem;
    }
    
    .job-info-item {
        background: #f8fafc;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #3b82f6;
        border: 1px solid #e2e8f0;
    }
    
    .job-info-label {
        font-size: 0.85rem;
        color: #64748b;
        font-weight: 600;
        margin-bottom: 0.3rem;
        display: flex;
        align-items: center;
        gap: 0.4rem;
    }
    
    .job-info-value {
        font-size: 1rem;
        color: #1e293b;
        font-weight: 600;
    }
    
    /* æˆåŠŸãƒœãƒƒã‚¯ã‚¹ */
    .success-box {
        background: #f0fdf4;
        border: 2px solid #22c55e;
        color: #15803d;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(34, 197, 94, 0.1);
    }
    
    .success-box h4 {
        color: #15803d;
        margin-bottom: 0.5rem;
    }
    
    /* è­¦å‘Šãƒœãƒƒã‚¯ã‚¹ */
    .warning-box {
        background: #fffbeb;
        border: 2px solid #f59e0b;
        color: #d97706;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(245, 158, 11, 0.1);
    }
    
    .warning-box h4 {
        color: #d97706;
        margin-bottom: 0.5rem;
    }
    
    /* æƒ…å ±ãƒœãƒƒã‚¯ã‚¹ */
    .info-box {
        background: #eff6ff;
        border: 2px solid #3b82f6;
        color: #1d4ed8;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.1);
    }
    
    .info-box h4 {
        color: #1d4ed8;
        margin-bottom: 0.5rem;
    }
    
    /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ */
    .metric-card {
        background: #ffffff;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(59, 130, 246, 0.15);
        border-color: #3b82f6;
    }
    
    .metric-value {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1e40af;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #64748b;
        font-weight: 600;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 0.3rem;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ */
    .sidebar-section {
        background: #ffffff;
        padding: 1.2rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 2px solid #e2e8f0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }
    
    .sidebar-section h4 {
        color: #1e40af;
        margin-bottom: 0.8rem;
        font-size: 1.1rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    .sidebar-section p, .sidebar-section li {
        color: #475569;
        font-size: 0.9rem;
        line-height: 1.6;
    }
    
    .sidebar-section ol li {
        margin-bottom: 0.5rem;
    }
    
    /* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸ */
    .status-badge {
        display: inline-flex;
        align-items: center;
        gap: 0.3rem;
        padding: 0.4rem 0.8rem;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    .status-created {
        background-color: #dcfce7;
        color: #15803d;
        border: 1px solid #22c55e;
    }
    
    .status-processing {
        background-color: #fef3c7;
        color: #d97706;
        border: 1px solid #f59e0b;
    }
    
    .status-completed {
        background-color: #dbeafe;
        color: #1d4ed8;
        border: 1px solid #3b82f6;
    }
    
    /* å°ã•ãªã‚¢ã‚¤ã‚³ãƒ³ */
    .small-icon {
        font-size: 0.8rem;
        margin-right: 0.2rem;
    }
    
    /* ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ */
    .section-header {
        color: #1e40af;
        font-size: 1.5rem;
        font-weight: 600;
        margin: 2rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #e2e8f0;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    /* Streamlitã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
    .stSelectbox > div > div {
        border: 2px solid #e2e8f0;
        border-radius: 8px;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: #3b82f6;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
    }
    
    .stTextInput > div > div > input {
        border: 2px solid #e2e8f0;
        border-radius: 8px;
        padding: 0.75rem;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #3b82f6;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%);
        border: none;
        color: white;
        border-radius: 8px;
        font-weight: 600;
        padding: 0.75rem 1.5rem;
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.2);
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #1d4ed8 0%, #1e3a8a 100%);
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(59, 130, 246, 0.3);
    }
    
    /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ */
    .stFileUploader > div {
        border: 2px dashed #3b82f6;
        border-radius: 12px;
        background: #f8fafc;
        padding: 2rem;
        text-align: center;
    }
    
    .stFileUploader > div:hover {
        background: #eff6ff;
        border-color: #1d4ed8;
    }
    
    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  */
    .stDataFrame {
        border: 2px solid #e2e8f0;
        border-radius: 8px;
        overflow: hidden;
    }
    
    /* ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ */
    .streamlit-expanderHeader {
        background-color: #f8fafc;
        border: 2px solid #e2e8f0;
        border-radius: 8px;
        color: #1e40af;
        font-weight: 600;
    }
    
    .streamlit-expanderHeader:hover {
        background-color: #eff6ff;
        border-color: #3b82f6;
    }
    
    /* ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®å¼·èª¿ */
    .download-section {
        background: #f0fdf4;
        border: 2px solid #22c55e;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        text-align: center;
    }
    
    /* ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ« */
    .stDownloadButton > button {
        background: linear-gradient(135deg, #22c55e 0%, #16a34a 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        font-weight: 600 !important;
        font-size: 1.1rem !important;
        padding: 1rem 2rem !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 6px rgba(34, 197, 94, 0.2) !important;
    }
    
    .stDownloadButton > button:hover {
        background: linear-gradient(135deg, #16a34a 0%, #15803d 100%) !important;
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 12px rgba(34, 197, 94, 0.3) !important;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¸ãƒ§ãƒ–å±¥æ­´ç®¡ç†
class JobHistoryManager:
    def __init__(self):
        self.history_file = Path("job_history.json")
        self.download_cache_dir = Path("download_cache")
        self.download_cache_dir.mkdir(exist_ok=True)
    
    def save_jobs(self, jobs):
        """ã‚¸ãƒ§ãƒ–å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            serializable_jobs = []
            for job in jobs:
                job_copy = job.copy()
                if isinstance(job_copy.get('created_at'), datetime):
                    job_copy['created_at'] = job_copy['created_at'].isoformat()
                serializable_jobs.append(job_copy)
            
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_jobs, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.error(f"ã‚¸ãƒ§ãƒ–å±¥æ­´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def load_jobs(self):
        """ã‚¸ãƒ§ãƒ–å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        if not self.history_file.exists():
            return []
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                jobs = json.load(f)
            
            # æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            for job in jobs:
                if isinstance(job.get('created_at'), str):
                    job['created_at'] = datetime.fromisoformat(job['created_at'])
            
            # ä½œæˆæ—¥æ™‚ã®é™é †ã§ã‚½ãƒ¼ãƒˆ
            jobs.sort(key=lambda x: x['created_at'], reverse=True)
            return jobs
        except Exception as e:
            st.error(f"ã‚¸ãƒ§ãƒ–å±¥æ­´ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return []
    
    def add_job(self, job):
        """æ–°ã—ã„ã‚¸ãƒ§ãƒ–ã‚’è¿½åŠ """
        jobs = self.load_jobs()
        jobs.insert(0, job)
        self.save_jobs(jobs)
    
    def update_job(self, job_id, updates):
        """ã‚¸ãƒ§ãƒ–ã‚’æ›´æ–°"""
        jobs = self.load_jobs()
        for job in jobs:
            if job['job_id'] == job_id:
                job.update(updates)
                break
        self.save_jobs(jobs)
    
    def get_job(self, job_id):
        """ç‰¹å®šã®ã‚¸ãƒ§ãƒ–ã‚’å–å¾—"""
        jobs = self.load_jobs()
        for job in jobs:
            if job['job_id'] == job_id:
                return job
        return None
    
    def cache_download_file(self, job_id, file_type, df):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        cache_path = self.download_cache_dir / f"{job_id}_{file_type}.xlsx"
        df.to_excel(cache_path, index=False)
        return cache_path

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
class DataManager:
    def __init__(self):
        self.base_dir = Path("jobs")
        self.base_dir.mkdir(exist_ok=True)
    
    def normalize_text(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ï¼ˆå…¨è§’â†’åŠè§’ã€ç©ºç™½å‰Šé™¤ãªã©ï¼‰"""
        if pd.isna(text):
            return ""
        text = str(text)
        # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«å¤‰æ›
        text = text.translate(str.maketrans(
            'ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™',
            'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
        ))
        # ç©ºç™½ã‚’å‰Šé™¤
        text = re.sub(r'\s+', '', text)
        return str(text).strip()
    
    def normalize_phone(self, phone_str):
        """é›»è©±ç•ªå·ã‚’æ­£è¦åŒ–ï¼ˆ+81å½¢å¼ã‚’0å§‹ã¾ã‚Šã«å¤‰æ›ï¼‰"""
        if pd.isna(phone_str):
            return ""
        phone_str = str(phone_str).strip()
        # +81ã‚’0ã«å¤‰æ›
        phone_str = re.sub(r'^\+81\s*', '0', phone_str)
        # ãƒã‚¤ãƒ•ãƒ³ã‚„ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
        phone_str = re.sub(r'[\s\-()]', '', phone_str)
        return str(phone_str).strip()
    
    def create_row_key(self, company, phone=""):
        """è¡ŒæŒ‡ç´‹ã‚’ä½œæˆï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ã€é›»è©±ç•ªå·ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
        # ç¤¾åã‚’æ­£è¦åŒ–ã—ã¦ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
        normalized_company = self.normalize_text(company)
        normalized_phone = self.normalize_phone(phone) if phone else ""
        base = f"{normalized_company}|{normalized_phone}"
        return hashlib.sha256(base.encode('utf-8')).hexdigest()[:16]
    
    def process_filemaker_data(self, df, job_id, output_filename):
        """ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        job_dir = self.base_dir / job_id
        job_dir.mkdir(exist_ok=True)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        original_path = job_dir / "fm_export.csv"
        df.to_csv(original_path, index=False, encoding='utf-8-sig')
        
        # AIãƒ†ãƒ¬ã‚¢ãƒç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›
        upload_df = df.copy()
        
        # ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹CSVã®å ´åˆã€ã€Œç¤¾åã€åˆ—ã¨ã€Œä½æ‰€çµ±åˆã€åˆ—ãŒã‚ã‚‹
        # é›»è©±ç•ªå·åˆ—ãŒãªã„å ´åˆã¯ç©ºåˆ—ã‚’è¿½åŠ 
        if 'é›»è©±ç•ªå·' not in upload_df.columns:
            upload_df['é›»è©±ç•ªå·'] = ""
        
        # å¿…è¦ãªåˆ—ã®ã¿æŠ½å‡ºï¼ˆAIãƒ†ãƒ¬ã‚¢ãƒç”¨ï¼‰
        required_columns = ['ç¤¾å', 'é›»è©±ç•ªå·', 'ä½æ‰€çµ±åˆ']
        available_columns = [col for col in required_columns if col in upload_df.columns]
        
        if available_columns:
            upload_df = upload_df[available_columns].copy()
        
        # ç¤¾åã‚’50æ–‡å­—ã§ã‚«ãƒƒãƒˆ
        if 'ç¤¾å' in upload_df.columns:
            upload_df['ç¤¾å'] = upload_df['ç¤¾å'].astype(str).str[:50]
        
        # è¡ŒæŒ‡ç´‹ã‚’ä½œæˆã—ã¦rowmapã‚’ç”Ÿæˆ(ç¤¾åãƒ™ãƒ¼ã‚¹)
        rowmap_data = []
        for idx, row in df.iterrows():
            company = row.get('ç¤¾å', '')
            phone = row.get('é›»è©±ç•ªå·', '') if 'é›»è©±ç•ªå·' in df.columns else ''
            row_key = self.create_row_key(company, phone)
            
            rowmap_data.append({
                'row_key': row_key,
                'company': company,
                'company_normalized': self.normalize_text(company),
                'phone': phone,
                'address': row.get('ä½æ‰€çµ±åˆ', ''),
                'index_in_fm': idx
            })
        
        rowmap_df = pd.DataFrame(rowmap_data)
        rowmap_path = job_dir / "rowmap.csv"
        rowmap_df.to_csv(rowmap_path, index=False, encoding='utf-8-sig')
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨CSVã‚’ä¿å­˜ï¼ˆUTF-8 with BOMï¼‰
        upload_path = job_dir / f"{output_filename}.csv"
        try:
            # ã¾ãšShift-JISã‚’è©¦ã™
            upload_df.to_csv(upload_path, index=False, encoding='shift_jis')
        except UnicodeEncodeError:
            # Shift-JISã§ä¿å­˜ã§ããªã„å ´åˆã¯UTF-8 with BOMã‚’ä½¿ç”¨
            upload_df.to_csv(upload_path, index=False, encoding='utf-8-sig')
        
        # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ä½œæˆ
        manifest = {
            'job_id': job_id,
            'created_at': datetime.now().isoformat(),
            'original_filename': output_filename,
            'total_rows': len(df),
            'files': {
                'fm_export': 'fm_export.csv',
                'upload': f'{output_filename}.csv',
                'rowmap': 'rowmap.csv'
            }
        }
        
        manifest_path = job_dir / "manifest.json"
        with open(manifest_path, 'w', encoding='utf-8') as f:
            json.dump(manifest, f, ensure_ascii=False, indent=2)
        
        return {
            'job_id': job_id,
            'upload_path': upload_path,
            'total_rows': len(df),
            'manifest': manifest
        }
    
    def analyze_call_results(self, df):
        """é€šè©±çµæœã‚’åˆ†æ"""
        # é›»è©±ç•ªå·ã‚’æ­£è¦åŒ–
        if 'é›»è©±ç•ªå·' in df.columns:
            df["é›»è©±ç•ªå·"] = df["é›»è©±ç•ªå·"].astype(str).str.replace(r'^\+81\s*', '0', regex=True)
            df["é›»è©±ç•ªå·"] = df["é›»è©±ç•ªå·"].str.replace(" ", "")
        
        # é€šè©±æ™‚é–“ã‚’æ•°å€¤åŒ–
        df["é€šè©±æ™‚é–“_num"] = pd.to_numeric(df["é€šè©±æ™‚é–“"], errors="coerce")
        
        # æ–­ã‚Šãƒ»çµ‚äº†ç³»ãƒ¯ãƒ¼ãƒ‰
        ng_words = [
            "æ–­ã‚Š", "ä¸è¦", "å¿…è¦ãªã„", "çµæ§‹ã§ã™", "çµæ§‹",
            "é›»è©±ãŒçµ‚äº†", "é›»è©±ã‚’åˆ‡ã£ãŸ", "åˆ‡æ–­", "å¿œç­”ãªã—", "å¿œç­”ç„¡ã—",
            "åˆ‡ã‚‰ã‚Œ", "åˆ‡ã‚‰ã‚Œã‚‹", "åˆ‡ã£ãŸ", "é€šè©±ãŒçµ‚äº†", "ä¼šè©±ãŒçµ‚äº†",
            "é€²å±•ã—ãªã„", "é€šè©±ã‚’çµ‚äº†", "é€²ã¾ãªã‹ã£ãŸ", "åˆ‡ã‚Šã¾ã—ãŸ", "æ–­å¿µ",
            "çµ‚äº†", "æˆç«‹ã—ãªã‹ã£ãŸ", "åˆ‡", "é€²å±•ã¯ã‚ã‚Šã¾"
        ]
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†é¡
        for idx, row in df.iterrows():
            status = str(row["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"])
            result = str(row["æ¶é›»çµæœ"]) if pd.notna(row["æ¶é›»çµæœ"]) else ""
            summary = str(row["è¦ç´„"]) if pd.notna(row["è¦ç´„"]) else ""
            duration = row["é€šè©±æ™‚é–“_num"]
            
            # æ—¢ã«çµæœãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if result.strip() != "" and result.strip() != "nan":
                continue
            
            # ç•™å®ˆç•ªé›»è©± â†’ ç•™å®ˆé›»
            if status.strip() == "ç•™å®ˆç•ªé›»è©±":
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆé›»"
                continue
            
            # å¿œç­”ãªã— â†’ ç•™å®ˆ
            if status.strip() in ["å¿œç­”ãªã—", "å¿œç­”ç„¡ã—"]:
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆ"
                continue
            
            # ç²å¾— â†’ AIé›»è©±APO
            if status.strip() == "ç²å¾—":
                df.at[idx, "æ¶é›»çµæœ"] = "AIé›»è©±APO"
                continue
            
            # è¦ç´„ã«æ–­ã‚Šãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ â†’ NG
            if any(word in summary for word in ng_words):
                df.at[idx, "æ¶é›»çµæœ"] = "NG"
                continue
            
            # é€šè©±æ™‚é–“ãŒ0 â†’ ç•™å®ˆ
            if duration == 0:
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆ"
                continue
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè‡ªå‹•éŸ³å£° â†’ ç•™å®ˆé›»
            if status.strip() == "è‡ªå‹•éŸ³å£°":
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆé›»"
                continue
            
            # è¦ç´„ã«ã€Œå¿œç­”ãªã—ã€ â†’ ç•™å®ˆ
            if any(x in summary for x in ["å¿œç­”ãªã—", "å¿œç­”ç„¡ã—"]):
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆ"
                continue
            
            # è¦ç´„ã«ã€Œè»¢é€ã€ã‚„ã€Œäº†æ‰¿ã—ã¾ã—ãŸã€ãªã© â†’ é›»è©±APO
            if any(x in summary for x in ["è»¢é€ã•ã‚ŒãŸ", "äº†æ‰¿ã—ã¾ã—ãŸ", "è»¢é€ã•ã‚Œã¾ã—ãŸ"]):
                df.at[idx, "æ¶é›»çµæœ"] = "AIé›»è©±APO"
                continue
            
            # é€šè©±æ™‚é–“ã‚ã‚Š & è»¢é€ã§ãªã„ â†’ NG
            if pd.notna(duration) and duration > 0 and not any(x in summary for x in ["è»¢é€"]):
                df.at[idx, "æ¶é›»çµæœ"] = "NG"
        
        return df
    
    def merge_with_original(self, call_results_df, job_id):
        """å…ƒãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸ï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ï¼‰"""
        job_dir = self.base_dir / job_id
        
        # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
        manifest_path = job_dir / "manifest.json"
        with open(manifest_path, 'r', encoding='utf-8') as f:
            manifest = json.load(f)
        
        # rowmapã‚’èª­ã¿è¾¼ã¿
        rowmap_path = job_dir / "rowmap.csv"
        rowmap_df = pd.read_csv(rowmap_path, encoding='utf-8-sig')
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        original_path = job_dir / "fm_export.csv"
        original_df = pd.read_csv(original_path, encoding='utf-8-sig')
        
        # é€šè©±çµæœã®ç¤¾åã‚’æ­£è¦åŒ–
        call_results_df['ç¤¾å_æ­£è¦åŒ–'] = call_results_df['ç¤¾å'].apply(self.normalize_text)
        
        # æ¶é›»æ™‚åˆ»åˆ—ã‚’ä¿æŒï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        has_call_time = 'æ¶é›»æ™‚åˆ»' in call_results_df.columns
        
        # æ¶é›»æ™‚åˆ»ã‚’æ—¥ä»˜ã¨æ™‚é–“ã«åˆ†å‰²
        if has_call_time:
            try:
                # æ¶é›»æ™‚åˆ»ã‚’æ—¥æ™‚å‹ã«å¤‰æ›
                call_results_df['æ¶é›»æ™‚åˆ»_dt'] = pd.to_datetime(call_results_df['æ¶é›»æ™‚åˆ»'], errors='coerce')
                # æ—¥ä»˜åˆ—ã‚’ä½œæˆï¼ˆYYYY/MM/DDå½¢å¼ï¼‰
                call_results_df['æ¶é›»æ—¥'] = call_results_df['æ¶é›»æ™‚åˆ»_dt'].dt.strftime('%Y/%m/%d')
                # æ™‚é–“åˆ—ã‚’ä½œæˆï¼ˆHH:MM:SSå½¢å¼ï¼‰
                call_results_df['æ¶é›»æ™‚é–“'] = call_results_df['æ¶é›»æ™‚åˆ»_dt'].dt.strftime('%H:%M:%S')
                # ä¸€æ™‚åˆ—ã‚’å‰Šé™¤
                call_results_df = call_results_df.drop('æ¶é›»æ™‚åˆ»_dt', axis=1)
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å…ƒã®æ¶é›»æ™‚åˆ»ã‚’ãã®ã¾ã¾ä½¿ç”¨
                pass
        
        # ç¤¾åãƒ™ãƒ¼ã‚¹ã§ãƒãƒ¼ã‚¸
        merged_df = pd.merge(
            call_results_df, 
            rowmap_df[['company_normalized', 'company', 'address']], 
            left_on='ç¤¾å_æ­£è¦åŒ–', 
            right_on='company_normalized', 
            how='left'
        )
        
        # é€šè©±çµæœã«è¡ŒæŒ‡ç´‹ã‚’è¿½åŠ 
        merged_df['row_key'] = merged_df.apply(
            lambda row: self.create_row_key(row.get('ç¤¾å', ''), row.get('é›»è©±ç•ªå·', '')), 
            axis=1
        )
        
        # åˆ—ã®é †åºã‚’æ•´ç†ï¼ˆæ¶é›»æ—¥ãƒ»æ¶é›»æ™‚é–“ã‚’å«ã‚ã‚‹ï¼‰
        if has_call_time and 'æ¶é›»æ—¥' in merged_df.columns and 'æ¶é›»æ™‚é–“' in merged_df.columns:
            column_order = ['ç¤¾å', 'é›»è©±ç•ªå·', 'æ¶é›»æ—¥', 'æ¶é›»æ™‚é–“', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ¶é›»çµæœ', 'è¦ç´„', 'é€šè©±æ™‚é–“', 
                           'ä½æ‰€çµ±åˆ', 'row_key']
        elif has_call_time:
            # åˆ†å‰²ã§ããªã‹ã£ãŸå ´åˆã¯å…ƒã®æ¶é›»æ™‚åˆ»ã‚’ä½¿ç”¨
            column_order = ['ç¤¾å', 'é›»è©±ç•ªå·', 'æ¶é›»æ™‚åˆ»', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ¶é›»çµæœ', 'è¦ç´„', 'é€šè©±æ™‚é–“', 
                           'ä½æ‰€çµ±åˆ', 'row_key']
        else:
            column_order = ['ç¤¾å', 'é›»è©±ç•ªå·', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ¶é›»çµæœ', 'è¦ç´„', 'é€šè©±æ™‚é–“', 
                           'ä½æ‰€çµ±åˆ', 'row_key']
        
        # ä½æ‰€çµ±åˆåˆ—ã‚’å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
        if 'address' in merged_df.columns:
            merged_df['ä½æ‰€çµ±åˆ'] = merged_df['address']
        
        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’é¸æŠ
        available_columns = [col for col in column_order if col in merged_df.columns]
        merged_df = merged_df[available_columns]
        
        return merged_df
    
    def calculate_statistics(self, df):
        """çµ±è¨ˆã‚’è¨ˆç®—"""
        def parse_duration(val):
            if pd.isna(val):
                return 0
            val = str(val).strip()
            if val in ["", "-", "nan"]:
                return 0
            parts = val.split(":")
            try:
                if len(parts) == 3:  # hh:mm:ss
                    h, m, s = map(int, parts)
                    return h*3600 + m*60 + s
                elif len(parts) == 2:  # mm:ss
                    m, s = map(int, parts)
                    return m*60 + s
                else:
                    return int(val)  # ç§’æ•°
            except:
                return 0
        
        # é€šè©±æ™‚é–“ã‚’ç§’ã«å¤‰æ›
        df["é€šè©±æ™‚é–“_sec"] = df["é€šè©±æ™‚é–“"].apply(parse_duration)
        
        # çµ±è¨ˆè¨ˆç®—
        total_calls = len(df)
        result_counts = df["æ¶é›»çµæœ"].value_counts()
        valid_calls = df[~df["æ¶é›»çµæœ"].isin(["ç•™å®ˆ", "ç•™å®ˆç•ªé›»è©±"])].shape[0]
        total_time_sec = int(df["é€šè©±æ™‚é–“_sec"].sum())
        total_time_str = str(timedelta(seconds=total_time_sec))
        transfer_calls = df[df["æ¶é›»çµæœ"].str.contains("APO", na=False)].shape[0]
        
        # ç„¡åŠ¹ç•ªå·ï¼ˆé›»è©±ç•ªå·åˆ—ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        invalid_numbers = 0
        if 'é›»è©±ç•ªå·' in df.columns:
            df["é›»è©±ç•ªå·_str"] = df["é›»è©±ç•ªå·"].astype(str).str.replace(r"\D", "", regex=True)
            invalid_numbers = df[~df["é›»è©±ç•ªå·_str"].str.match(r"^0\d{9,10}$", na=False)].shape[0]
        
        # ã‚¨ãƒ©ãƒ¼ä»¶æ•°
        error_calls = df[df[["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "è¦ç´„"]].astype(str).apply(
            lambda x: any("ã‚¨ãƒ©ãƒ¼" in v for v in x), axis=1
        )].shape[0]
        
        return {
            'total_calls': total_calls,
            'valid_calls': valid_calls,
            'total_time': total_time_str,
            'transfer_calls': transfer_calls,
            'invalid_numbers': invalid_numbers,
            'error_calls': error_calls,
            'result_counts': result_counts.to_dict()
        }

# æ”¹è‰¯ã•ã‚ŒãŸã‚¸ãƒ§ãƒ–ã‚«ãƒ¼ãƒ‰è¡¨ç¤ºé–¢æ•°
def display_job_card(job):
    """è¦‹ã‚„ã™ã„ã‚¸ãƒ§ãƒ–ã‚«ãƒ¼ãƒ‰ã‚’è¡¨ç¤º"""
    status_class = f"status-{job.get('status', 'created')}"
    created_at = job['created_at']
    if isinstance(created_at, str):
        created_at = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
    
    status_emoji = {
        'created': 'âœ…',
        'processing': 'â³',
        'completed': 'ğŸ‰'
    }
    
    status_text = {
        'created': 'ä½œæˆæ¸ˆã¿',
        'processing': 'å‡¦ç†ä¸­',
        'completed': 'å®Œäº†'
    }
    
    st.markdown(f"""
    <div class="job-card">
        <div class="job-card-header">
            <span>{status_emoji.get(job.get('status', 'created'), 'ğŸ“„')} {job['filename']}</span>
            <span class="status-badge {status_class}">{status_text.get(job.get('status', 'created'), 'ä¸æ˜')}</span>
        </div>
        <div class="job-info-grid">
            <div class="job-info-item">
                <div class="job-info-label">ğŸ“… ä½œæˆæ—¥æ™‚</div>
                <div class="job-info-value">{created_at.strftime('%Y/%m/%d %H:%M')}</div>
            </div>
            <div class="job-info-item">
                <div class="job-info-label">ğŸ”¢ ã‚¸ãƒ§ãƒ–ID</div>
                <div class="job-info-value">{job['job_id'][:8]}...</div>
            </div>
            <div class="job-info-item">
                <div class="job-info-label">ğŸ“Š ä»¶æ•°</div>
                <div class="job-info-value">{job['total_rows']:,}ä»¶</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    st.markdown('<h1 class="main-header">ğŸ“ AIãƒ†ãƒ¬ã‚¢ãƒç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç¨ç†å£«ã‚¢ãƒã‚·ã‚¹ç‰ˆï¼‰</h1>', unsafe_allow_html=True)
    
    # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    history_manager = JobHistoryManager()
    data_manager = DataManager()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.markdown("""
        <div class="sidebar-section">
            <h4>ğŸ“– ä½¿ã„æ–¹</h4>
            <ol>
                <li><strong>CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</strong><br>ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç¤¾åã€ä½æ‰€çµ±åˆåˆ—ã‚’å«ã‚€ï¼‰</li>
                <li><strong>AIãƒ†ãƒ¬ã‚¢ãƒç”¨CSVã‚’ç”Ÿæˆ</strong><br>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦AIãƒ†ãƒ¬ã‚¢ãƒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</li>
                <li><strong>é€šè©±çµæœã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</strong><br>AIãƒ†ãƒ¬ã‚¢ãƒã‹ã‚‰è¿”å´ã•ã‚ŒãŸCSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</li>
                <li><strong>åˆ†æçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</strong><br>å…ƒãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸ã•ã‚ŒãŸçµæœã‚’å–å¾—</li>
            </ol>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="sidebar-section">
            <h4>â„¹ï¸ æ³¨æ„äº‹é …</h4>
            <p>â€¢ ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹CSVã¯ã€Œç¤¾åã€ã€Œä½æ‰€çµ±åˆã€åˆ—ãŒå¿…é ˆã§ã™</p>
            <p>â€¢ é›»è©±ç•ªå·åˆ—ãŒãªã„å ´åˆã¯ç©ºåˆ—ãŒè¿½åŠ ã•ã‚Œã¾ã™</p>
            <p>â€¢ ç¤¾åã¯50æ–‡å­—ã¾ã§è‡ªå‹•ã‚«ãƒƒãƒˆã•ã‚Œã¾ã™</p>
            <p>â€¢ é€šè©±çµæœã¯ç¤¾åãƒ™ãƒ¼ã‚¹ã§ãƒãƒƒãƒãƒ³ã‚°ã•ã‚Œã¾ã™</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2 = st.tabs(["ğŸ“¤ æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“‹ ã‚¸ãƒ§ãƒ–å±¥æ­´"])
    
    with tab1:
        st.markdown('<h2 class="section-header">ğŸ“¤ ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹CSVã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h2>', unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=['csv'],
            help="ç¤¾åã€ä½æ‰€çµ±åˆåˆ—ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file:
            try:
                # CSVã‚’èª­ã¿è¾¼ã¿ï¼ˆUTF-8 with BOMã«å¯¾å¿œï¼‰
                df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                
                st.markdown(f"""
                <div class="info-box">
                    <h4>âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ</h4>
                    <p><strong>ãƒ•ã‚¡ã‚¤ãƒ«å:</strong> {uploaded_file.name}</p>
                    <p><strong>ãƒ‡ãƒ¼ã‚¿ä»¶æ•°:</strong> {len(df):,}ä»¶</p>
                    <p><strong>åˆ—æ•°:</strong> {len(df.columns)}åˆ—</p>
                </div>
                """, unsafe_allow_html=True)
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
                    st.dataframe(df.head(10), use_container_width=True)
                
                # åˆ—ã®ç¢ºèª
                required_cols = ['ç¤¾å', 'ä½æ‰€çµ±åˆ']
                missing_cols = [col for col in required_cols if col not in df.columns]
                
                if missing_cols:
                    st.markdown(f"""
                    <div class="warning-box">
                        <h4>âš ï¸ å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™</h4>
                        <p>ä»¥ä¸‹ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_cols)}</p>
                        <p>ç¨ç†å£«ã‚¢ãƒã‚·ã‚¹CSVã«ã¯ã€Œç¤¾åã€ã€Œä½æ‰€çµ±åˆã€åˆ—ãŒå¿…è¦ã§ã™ã€‚</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    # å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
                    if st.button("ğŸš€ AIãƒ†ãƒ¬ã‚¢ãƒç”¨CSVã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
                        with st.spinner("å‡¦ç†ä¸­..."):
                            # ã‚¸ãƒ§ãƒ–IDã‚’ç”Ÿæˆ
                            job_id = hashlib.sha256(f"{uploaded_file.name}{datetime.now().isoformat()}".encode()).hexdigest()[:16]
                            
                            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
                            output_filename = uploaded_file.name.replace('.csv', '_ai_teleapo')
                            
                            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                            result = data_manager.process_filemaker_data(df, job_id, output_filename)
                            
                            # ã‚¸ãƒ§ãƒ–ã‚’å±¥æ­´ã«è¿½åŠ 
                            job = {
                                'job_id': job_id,
                                'filename': uploaded_file.name,
                                'created_at': datetime.now(),
                                'total_rows': result['total_rows'],
                                'status': 'created'
                            }
                            history_manager.add_job(job)
                            
                            st.markdown(f"""
                            <div class="success-box">
                                <h4>ğŸ‰ å‡¦ç†å®Œäº†!</h4>
                                <p><strong>ã‚¸ãƒ§ãƒ–ID:</strong> {job_id}</p>
                                <p><strong>å‡¦ç†ä»¶æ•°:</strong> {result['total_rows']:,}ä»¶</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            with open(result['upload_path'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“¥ AIãƒ†ãƒ¬ã‚¢ãƒç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    data=f.read(),
                                    file_name=f"{output_filename}.csv",
                                    mime="text/csv",
                                    use_container_width=True
                                )
                            
                            st.info("ğŸ’¡ ã“ã®CSVã‚’AIãƒ†ãƒ¬ã‚¢ãƒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚é€šè©±å®Œäº†å¾Œã€çµæœCSVã‚’ã€Œã‚¸ãƒ§ãƒ–å±¥æ­´ã€ã‚¿ãƒ–ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
            
            except Exception as e:
                st.markdown(f"""
                <div class="warning-box">
                    <h4>âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h4>
                    <p>{str(e)}</p>
                </div>
                """, unsafe_allow_html=True)
    
    with tab2:
        st.markdown('<h2 class="section-header">ğŸ“‹ ã‚¸ãƒ§ãƒ–å±¥æ­´</h2>', unsafe_allow_html=True)
        
        jobs = history_manager.load_jobs()
        
        if not jobs:
            st.markdown("""
            <div class="info-box">
                <h4>ğŸ“­ ã‚¸ãƒ§ãƒ–å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“</h4>
                <p>ã€Œæ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚¿ãƒ–ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            # ã‚¸ãƒ§ãƒ–é¸æŠ
            job_options = {f"{job['filename']} ({job['created_at'].strftime('%Y/%m/%d %H:%M')})": job['job_id'] for job in jobs}
            selected_job_name = st.selectbox("ğŸ“‚ ã‚¸ãƒ§ãƒ–ã‚’é¸æŠ", list(job_options.keys()))
            selected_job_id = job_options[selected_job_name]
            
            # é¸æŠã•ã‚ŒãŸã‚¸ãƒ§ãƒ–ã®è©³ç´°è¡¨ç¤º
            selected_job = history_manager.get_job(selected_job_id)
            if selected_job:
                display_job_card(selected_job)
                
                # é€šè©±çµæœã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                st.markdown('<h3 class="section-header">ğŸ“¥ é€šè©±çµæœã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h3>', unsafe_allow_html=True)
                
                call_result_file = st.file_uploader(
                    "AIãƒ†ãƒ¬ã‚¢ãƒã‹ã‚‰ã®é€šè©±çµæœCSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    type=['csv'],
                    key=f"call_result_{selected_job_id}"
                )
                
                if call_result_file:
                    try:
                        # é€šè©±çµæœã‚’èª­ã¿è¾¼ã¿
                        call_results_df = pd.read_csv(call_result_file, encoding='utf-8-sig')
                        
                        st.markdown(f"""
                        <div class="info-box">
                            <h4>âœ… é€šè©±çµæœèª­ã¿è¾¼ã¿æˆåŠŸ</h4>
                            <p><strong>é€šè©±ä»¶æ•°:</strong> {len(call_results_df):,}ä»¶</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                        with st.expander("ğŸ“Š é€šè©±çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                            st.dataframe(call_results_df.head(10), use_container_width=True)
                        
                        # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
                        if st.button("ğŸ” åˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
                            with st.spinner("åˆ†æä¸­..."):
                                # é€šè©±çµæœã‚’åˆ†æ
                                analyzed_df = data_manager.analyze_call_results(call_results_df)
                                
                                # çµ±è¨ˆã‚’è¨ˆç®—
                                stats = data_manager.calculate_statistics(analyzed_df)
                                
                                # çµ±è¨ˆè¡¨ç¤º
                                st.markdown('<h3 class="section-header">ğŸ“Š åˆ†æçµæœ</h3>', unsafe_allow_html=True)
                                
                                col1, col2, col3, col4 = st.columns(4)
                                
                                with col1:
                                    st.markdown(f"""
                                    <div class="metric-card">
                                        <div class="metric-value">{stats['total_calls']}</div>
                                        <div class="metric-label">ğŸ“ ç·æ¶é›»æ•°</div>
                                    </div>
                                    """, unsafe_allow_html=True)
                                
                                with col2:
                                    st.markdown(f"""
                                    <div class="metric-card">
                                        <div class="metric-value">{stats['valid_calls']}</div>
                                        <div class="metric-label">âœ… æœ‰åŠ¹æ¶é›»æ•°</div>
                                    </div>
                                    """, unsafe_allow_html=True)
                                
                                with col3:
                                    st.markdown(f"""
                                    <div class="metric-card">
                                        <div class="metric-value">{stats['transfer_calls']}</div>
                                        <div class="metric-label">ğŸ¯ APOç²å¾—æ•°</div>
                                    </div>
                                    """, unsafe_allow_html=True)
                                
                                with col4:
                                    apo_rate = (stats['transfer_calls'] / stats['valid_calls'] * 100) if stats['valid_calls'] > 0 else 0
                                    st.markdown(f"""
                                    <div class="metric-card">
                                        <div class="metric-value">{apo_rate:.1f}%</div>
                                        <div class="metric-label">ğŸ“ˆ APOç‡</div>
                                    </div>
                                    """, unsafe_allow_html=True)
                                
                                # æ¶é›»çµæœã®å†…è¨³
                                st.markdown('<h4>ğŸ“‹ æ¶é›»çµæœã®å†…è¨³</h4>', unsafe_allow_html=True)
                                result_df = pd.DataFrame(list(stats['result_counts'].items()), columns=['æ¶é›»çµæœ', 'ä»¶æ•°'])
                                result_df['å‰²åˆ'] = (result_df['ä»¶æ•°'] / stats['total_calls'] * 100).round(1).astype(str) + '%'
                                st.dataframe(result_df, use_container_width=True)
                                
                                # å…ƒãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸ï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ï¼‰
                                merged_df = data_manager.merge_with_original(analyzed_df, selected_job_id)
                                
                                st.markdown('<h4>ğŸ“„ ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿</h4>', unsafe_allow_html=True)
                                st.dataframe(merged_df, use_container_width=True)
                                
                                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                                st.markdown('<div class="download-section">', unsafe_allow_html=True)
                                st.markdown('<h4>ğŸ’¾ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</h4>', unsafe_allow_html=True)
                                
                                # Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                                output = BytesIO()
                                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                    merged_df.to_excel(writer, sheet_name='é€šè©±çµæœ', index=False)
                                output.seek(0)
                                
                                st.download_button(
                                    label="ğŸ“¥ åˆ†æçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Excel)",
                                    data=output,
                                    file_name=f"{selected_job['filename'].replace('.csv', '')}_åˆ†æçµæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True
                                )
                                
                                st.markdown('</div>', unsafe_allow_html=True)
                                
                                # ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                                history_manager.update_job(selected_job_id, {'status': 'completed'})
                                
                    except Exception as e:
                        st.markdown(f"""
                        <div class="warning-box">
                            <h4>âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h4>
                            <p>{str(e)}</p>
                        </div>
                        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
